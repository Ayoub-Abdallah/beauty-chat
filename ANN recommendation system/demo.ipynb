{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27109b6",
   "metadata": {},
   "source": [
    "# Recommendation System Project Report\n",
    "\n",
    "## Overview\n",
    "This project implements a conversation-based product recommendation system for an online store. It uses semantic embeddings, business signals, and seller-controlled boosting to recommend relevant products based on user chat sessions.\n",
    "\n",
    "## How It Works\n",
    "1. **Conversation Understanding**: The system parses the last N user messages to extract intent (category, features, sentiment, budget, etc.), combining them into a single `session_text`.\n",
    "2. **Embeddings**: Both products and conversations are converted into vector embeddings using a pretrained SentenceTransformer model (`all-MiniLM-L6-v2`).\n",
    "3. **Similarity Search**: The system computes cosine similarity between the session embedding and all product embeddings to find the most relevant products.\n",
    "4. **Scoring and Ranking**: Each candidate product is scored using a composite formula that balances semantic similarity, category match, popularity, stock, recency, personalization, and seller boost. All components are normalized to [0,1].\n",
    "5. **Filtering**: Products are filtered by category (if mentioned), stock availability, and optionally by price range before scoring.\n",
    "6. **API Endpoints**: The FastAPI app exposes endpoints to get recommendations, update seller boost, and list products.\n",
    "\n",
    "## Project Structure\n",
    "```\n",
    "recommendation-system/\n",
    "├─ app.py\n",
    "├─ models/\n",
    "│   └─ recommender.py\n",
    "├─ data/\n",
    "│   ├─ products.json\n",
    "│   └─ conversations.json\n",
    "├─ utils/\n",
    "│   ├─ embeddings.py\n",
    "│   └─ scoring.py\n",
    "├─ requirements.txt\n",
    "└─ demo.ipynb\n",
    "```\n",
    "\n",
    "## How to Run\n",
    "1. **Install Dependencies**:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "2. **Start the API Server**:\n",
    "   ```bash\n",
    "   uvicorn app:app --reload\n",
    "   ```\n",
    "3. **Test the API**:\n",
    "   - Use the `/recommend` endpoint to get product recommendations based on a conversation.\n",
    "   - Use `/seller/boost` to update a product's seller boost.\n",
    "   - Use `/products` to list all products.\n",
    "4. **Explore the Notebook**:\n",
    "   - Open `demo.ipynb` to see step-by-step demonstrations of embeddings, similarity search, scoring, filtering, and the effect of seller boost.\n",
    "\n",
    "## Customization & Extension\n",
    "- Add more products to `products.json`.\n",
    "- Integrate with a real chatbot frontend.\n",
    "- Extend scoring logic for personalization, exploration, or logging user feedback.\n",
    "\n",
    "## Summary\n",
    "This system provides context-aware, fair, and business-driven product recommendations for conversational commerce, ready for integration and future extension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c75b8",
   "metadata": {},
   "source": [
    "# 1. Project Setup and Folder Structure\n",
    "\n",
    "This notebook demonstrates a complete Python recommendation system for conversation-based product recommendations in an online store.\n",
    "\n",
    "The recommended folder structure is:\n",
    "\n",
    "```\n",
    "recommendation-system/\n",
    "├─ app.py\n",
    "├─ models/\n",
    "│   └─ recommender.py\n",
    "├─ data/\n",
    "│   ├─ products.json\n",
    "│   └─ conversations.json\n",
    "├─ utils/\n",
    "│   ├─ embeddings.py\n",
    "│   └─ scoring.py\n",
    "├─ requirements.txt\n",
    "└─ demo.ipynb\n",
    "```\n",
    "\n",
    "Each file serves a specific purpose:\n",
    "- `app.py`: FastAPI entry point for the REST API.\n",
    "- `models/recommender.py`: Core recommendation logic.\n",
    "- `data/products.json`: Example product catalog.\n",
    "- `data/conversations.json`: Example chat sessions.\n",
    "- `utils/embeddings.py`: Embedding generator using SentenceTransformer.\n",
    "- `utils/scoring.py`: Composite scoring and ranking logic.\n",
    "- `requirements.txt`: Python dependencies.\n",
    "- `demo.ipynb`: This demonstration notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489bcd00",
   "metadata": {},
   "source": [
    "# 2. Sample Data Creation: Products and Conversations\n",
    "\n",
    "We use two JSON files for demonstration:\n",
    "\n",
    "- `products.json`: Contains 5–10 sample products, each with fields like id, title, description, category, popularity, stock, recency, personal, and seller_boost.\n",
    "- `conversations.json`: Contains sample chat sessions between users and the assistant.\n",
    "\n",
    "**Example products.json:**\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"id\": 1,\n",
    "    \"title\": \"Running Shoes Pro 2\",\n",
    "    \"description\": \"Lightweight breathable running shoes ideal for daily training.\",\n",
    "    \"category\": \"Sportswear\",\n",
    "    \"popularity\": 0.8,\n",
    "    \"stock\": 1,\n",
    "    \"recency\": 0.6,\n",
    "    \"personal\": 0.0,\n",
    "    \"seller_boost\": 0.3\n",
    "  },\n",
    "  // ... more products ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Example conversations.json:**\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"session_id\": 101,\n",
    "    \"messages\": [\n",
    "      \"Hi there, I'm looking for some new running shoes.\",\n",
    "      \"I like lightweight and breathable materials.\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd94dab",
   "metadata": {},
   "source": [
    "# 3. Embedding Generation for Products and Conversations\n",
    "\n",
    "We use the SentenceTransformer model (`all-MiniLM-L6-v2`) to generate embeddings for both products and user conversations.\n",
    "\n",
    "- Product embeddings are precomputed for each product's title and description.\n",
    "- Conversation embeddings are generated by combining the last N user messages into a single `session_text`.\n",
    "\n",
    "This enables semantic similarity search between user intent and product catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load products and conversations\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "with open('data/products.json', 'r') as f:\n",
    "    products = json.load(f)\n",
    "with open('data/conversations.json', 'r') as f:\n",
    "    conversations = json.load(f)\n",
    "\n",
    "# Initialize embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate product embeddings\n",
    "product_texts = [p['title'] + ' ' + p['description'] for p in products]\n",
    "product_embeddings = model.encode(product_texts)\n",
    "\n",
    "# Example: Generate embedding for a conversation session\n",
    "session = conversations[0]['messages']\n",
    "session_text = ' '.join(session)\n",
    "session_embedding = model.encode([session_text])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa9c30c",
   "metadata": {},
   "source": [
    "# 4. Cosine Similarity kNN Search Implementation\n",
    "\n",
    "To find the most relevant products for a conversation, we use numpy-based cosine similarity between the session embedding and each product embedding.\n",
    "\n",
    "This allows us to efficiently retrieve the top-K most similar products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Compute similarities\n",
    "similarities = [cosine_similarity(session_embedding, emb) for emb in product_embeddings]\n",
    "\n",
    "# Get top-5 products by similarity\n",
    "top_k = 5\n",
    "indices = np.argsort(similarities)[::-1][:top_k]\n",
    "top_products = [products[i] for i in indices]\n",
    "\n",
    "for i, prod in enumerate(top_products):\n",
    "    print(f\"{i+1}. {prod['title']} (Category: {prod['category']}) - Similarity: {similarities[indices[i]]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45c7c2",
   "metadata": {},
   "source": [
    "# 5. Scoring and Ranking Logic\n",
    "\n",
    "Each candidate product is scored using a composite formula:\n",
    "\n",
    "```\n",
    "final_score = base * (1 + clip(seller_boost, 0, max_boost))\n",
    "base = w_sim*sim + w_cat*cat + w_pop*pop + w_stock*stock + w_recency*recency + w_personal*personal\n",
    "```\n",
    "\n",
    "Weights:\n",
    "- w_sim=0.6, w_cat=0.15, w_pop=0.1, w_stock=0.05, w_recency=0.05, w_personal=0.05\n",
    "- max_boost=0.25\n",
    "\n",
    "All components are normalized to [0,1].\n",
    "\n",
    "This balances semantic relevance, business signals, personalization, and seller boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, min_val=0, max_val=1):\n",
    "    return max(min((x - min_val) / (max_val - min_val), 1.0), 0.0)\n",
    "\n",
    "def compute_score(sim, cat, pop, stock, recency, personal, seller_boost, max_boost=0.25):\n",
    "    w_sim = 0.6\n",
    "    w_cat = 0.15\n",
    "    w_pop = 0.1\n",
    "    w_stock = 0.05\n",
    "    w_recency = 0.05\n",
    "    w_personal = 0.05\n",
    "    base = w_sim*sim + w_cat*cat + w_pop*pop + w_stock*stock + w_recency*recency + w_personal*personal\n",
    "    final_score = base * (1 + min(max(seller_boost, 0), max_boost))\n",
    "    return final_score\n",
    "\n",
    "# Example scoring for top products\n",
    "for prod in top_products:\n",
    "    sim = 1.0  # Already top by similarity\n",
    "    cat = 1.0 if prod['category'].lower() in session_text.lower() else 0.5\n",
    "    pop = normalize(prod['popularity'])\n",
    "    stock = normalize(prod['stock'])\n",
    "    recency = normalize(prod['recency'])\n",
    "    personal = normalize(prod['personal'])\n",
    "    seller_boost = prod.get('seller_boost', 0.0)\n",
    "    score = compute_score(sim, cat, pop, stock, recency, personal, seller_boost)\n",
    "    print(f\"{prod['title']} - Final Score: {score:.2f} (Boost: {seller_boost})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783219e",
   "metadata": {},
   "source": [
    "# 6. Filtering by Category, Stock, and Price\n",
    "\n",
    "Before scoring, products are filtered by:\n",
    "- Category (if mentioned in the conversation)\n",
    "- Stock > 0 (only available products)\n",
    "- Optionally by price range (if price is mentioned)\n",
    "\n",
    "This ensures recommendations are relevant and available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad349556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Filter products by category and stock\n",
    "category = None\n",
    "for msg in session:\n",
    "    for cat in set([p['category'] for p in products]):\n",
    "        if cat.lower() in msg.lower():\n",
    "            category = cat\n",
    "            break\n",
    "\n",
    "filtered_products = [p for p in products if p['stock'] > 0 and (not category or p['category'].lower() == category.lower())]\n",
    "print(f\"Filtered products: {[p['title'] for p in filtered_products]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951cd38",
   "metadata": {},
   "source": [
    "# 7. API Endpoints with FastAPI\n",
    "\n",
    "The REST API is implemented using FastAPI in `app.py`:\n",
    "\n",
    "- `POST /recommend`: Returns top-N product recommendations for a given conversation.\n",
    "- `POST /seller/boost`: Updates a product's seller_boost value.\n",
    "- `GET /products`: Returns all products with metadata.\n",
    "\n",
    "Example usage:\n",
    "```python\n",
    "import requests\n",
    "resp = requests.post('http://localhost:8000/recommend', json={\"conversation\": session})\n",
    "print(resp.json())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a5c81",
   "metadata": {},
   "source": [
    "# 8. Demo: Conversation Embedding and Top-5 Recommendations\n",
    "\n",
    "This section demonstrates how to:\n",
    "- Embed a user conversation\n",
    "- Run kNN search\n",
    "- Print top-5 recommendations with explanations\n",
    "\n",
    "You can use the code above to generate embeddings and scores, and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top-5 recommendations with explanations\n",
    "for i, prod in enumerate(top_products):\n",
    "    reason = \"Recommended because you mentioned running and breathable shoes.\" if \"running\" in session_text.lower() and \"breathable\" in prod['description'].lower() else f\"Relevant to your interest in {prod['category']} products.\"\n",
    "    print(f\"{i+1}. {prod['title']} (Score: {similarities[indices[i]]:.2f}) - {reason}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7dcc8",
   "metadata": {},
   "source": [
    "# 9. Demo: Effect of Seller Boost on Ranking\n",
    "\n",
    "You can change the `seller_boost` value for a product and observe its effect on the ranking and final score.\n",
    "\n",
    "Increasing seller_boost (up to max_boost) will increase the product's chance of being recommended, while maintaining fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change seller_boost for a product and recompute score\n",
    "prod = top_products[0]\n",
    "old_boost = prod['seller_boost']\n",
    "prod['seller_boost'] = 0.25  # Max boost\n",
    "score = compute_score(1.0, 1.0, normalize(prod['popularity']), normalize(prod['stock']), normalize(prod['recency']), normalize(prod['personal']), prod['seller_boost'])\n",
    "print(f\"After boost: {prod['title']} - Final Score: {score:.2f} (Boost: {prod['seller_boost']})\")\n",
    "# Restore original boost\n",
    "prod['seller_boost'] = old_boost\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
